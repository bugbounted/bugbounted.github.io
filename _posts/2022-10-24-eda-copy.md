---
layout: post
title: استفاده از شبکه های عصبی و تعبیه کلمه NLP برای پیش بینی رتبه بندی بررسی کاربران
  آمازون
tags:
- علمی
- برنامه نویسی
- هوش مصنوعی
categories:
- AI

---
##   
![](https://miro.medium.com/max/400/1*YHPKTpGqvbilzmUQMvZ8LQ.jpeg)

# خلاصه

## هدف پروژه:

هدف از این پروژه ساخت مدلی بود که امتیاز ستاره یک کاربر (مقیاس 1 تا 5) را در آلبوم های موسیقی دیجیتال آمازون بر اساس متن نوشته شده در نظرات بررسی آنها پیش بینی کند. من چندین الگوریتم شبکه عصبی را آزمایش کردم که با نظرات نمونه‌ای از بررسی کاربران و رتبه‌بندی‌های ستاره مربوطه آنها آموزش داده شد. و من از چندین تکنیک پردازش زبان طبیعی (NLP) برای نشانه‌گذاری و بردار کردن متن در یک ساختار داده «قابل آموزش» استفاده کردم. با ساختن یک مدل طبقه‌بندی نظارت شده که نظر کاربر را از متن رمزگشایی می‌کند، امیدوارم الگوریتم من به طور بالقوه بتواند برای انواع دیگر مشکلات تحلیل احساسات، از جمله مواردی که نیاز به یادگیری بدون نظارت دارند (یعنی برچسب‌های طبقه‌بندی رتبه‌بندی ستاره‌ای برای آموزش ندارند) مورد استفاده قرار گیرد. البته این با این فرض است که امتیاز ستاره بازتابی واقعی از احساسات کاربر است.

همانطور که در جدول زیر نشان داده شده است، مدل من از داده‌های خام بررسی کاربر (ستون reviewText) نمونه می‌گیرد، متن را از کلمات کلیدی نشانه‌گذاری شده (ستون نشانه‌ها) بردار می‌کند، و سپس رتبه‌بندی ستاره کاربران را که می‌گذارند پیش‌بینی می‌کند. سپس می بینم که چگونه مقدار ستاره پیش بینی شده (pred_stars) با مقدار ستاره واقعی در مجموعه داده (diff_pred) مقایسه می شود.

![](https://miro.medium.com/max/700/1*4zped0QxsdhSnNutA45nrg.png)

## داده ها و کد مورد استفاده:

منبع باز [مجموعه داده ](http://jmcauley.ucsd.edu/data/amazon/)از آمازون با 1.5 میلیون بررسی کاربر بود. از آنجایی که لپ‌تاپ من محدودیت‌های پردازشی داشت و به سرور ابری دسترسی نداشت، ترجیح دادم فقط بر روی یک نمونه تصادفی 10٪ از مجموعه داده کامل آموزش/آزمایش کنم. تمام کدهای من را می توان در نوت بوک Jupyter [در اینجا یافت ](https://github.com/omshapira/Amazon_star_rating_predictions/blob/master/Project_Amazon_Reviews.ipynb).

## مروری بر روش شناسی:

برای ساخت این مدل، من به آزمایش و تنظیم هایپرپارامتر شش نوع مختلف الگوریتم و ترکیب برداری NLP پایان دادم. الگوریتم‌هایی که من بررسی کردم، مدل‌های ماشین بردار پشتیبانی (SVM)، شبکه عصبی عمیق (DNN) و شبکه عصبی کانولوشنال (CNN) بودند. برای بردار کردن داده های متن خود، سه روش را آزمایش کردم: کیسه کلمات (BOW)، آموزش بردار جاسازی کلمه از ابتدا، و استفاده از الگوریتم از پیش آموزش داده شده بردار جاسازی کلمه بردارهای جهانی برای نمایش کلمه ( [GloVe ](https://nlp.stanford.edu/projects/glove/)). هر یک از این مدل‌ها از همان گردش کار نشان داده شده در نمودار زیر پیروی می‌کنند. پس از نمونه‌برداری و پیش‌پردازش متن، داده‌ها به داده‌های آزمایشی و آموزشی تقسیم شدند.

![](https://miro.medium.com/max/700/1*G6mSlJDYCDMHer-6xUIOeQ.png)

## خلاصه نتایج:

همانطور که در نتایج زیر مشاهده می شود، DNN با برداری BOW بالاترین دقت 62٪ را داشت. در حالی که من از اینکه دقت همه مدل‌هایم فقط 60% بود ناامید بودم، خوشحال بودم که هر کدام ≥85% دقت در پیش‌بینی در یک رتبه ستاره داشتند. اما همانطور که با دقت تمرین بالا مشاهده می شود، همه مدل های من بیش از حد برازش به نظر می رسند.

![](https://miro.medium.com/max/700/1*aDfp235uQpwymKuP1E_Hdg.png)

مهم است که به خاطر داشته باشید که تفسیر عملکرد مدل‌های چند کلاسه (در این مورد، 5 برای هر ستاره) نسبت به مدل‌های باینری ساده‌تر است. برای مثال، ممکن است منطقی باشد که به [دقت وزنی ](https://www.datascienceblog.net/post/machine-learning/performance-measures-multi-class-problems/)یا عملکرد برای هر سطح کلاس (یعنی ستاره) نگاه کنیم. من یک بررسی عمیق تر از معیارهای عملکرد انجام ندادم، اما قصد دارم بعداً این را بررسی کنم. همانطور که گفته شد، من گمان می کنم که ترکیبی از مقصران وجود داشته باشد که باعث شده بیش از حد در مدل من مناسب شود. در سطح بالا، این موارد عبارتند از:

1. _مجموعه داده نامتعادل:_ نمونه داده های خام من بسیار کج بود و 80 درصد رتبه بندی ها دارای 5 ستاره بودند. در حالی که من از تکنیک‌های نمونه‌گیری مجدد برای بهبود یکنواختی توزیع استفاده کردم، همچنان نامتعادل باقی ماند. این تأثیر بر عملکرد می تواند به ویژه در مدل های چند کلاسه تشدید شود. با زمان بیشتر، من قصد دارم سایر تکنیک های over/sampling را بررسی کنم.
2. _پارامترهای جاسازی و آموزش_ : ممکن است در آموزش تعبیه کلمه من کمبودهایی وجود داشته باشد، یا در الگوریتم های NN/CNN من، فراپارامترهای غیربهینه (مانند لایه ها، فیلترها و غیره) وجود داشته باشد. من توابع منظم‌سازی را در Keras آزمایش کرده بودم، اما این منجر به کاهش دقت در داده‌های آموزشی من بدون بهبود عملکرد داده‌های اعتبارسنجی من شد. در حالی که من از GridSearch برای تنظیم فراپارامترهای مدل خود استفاده می‌کردم، زمان آموزشی زیادی که برای آموزش لازم بود، محدوده و تعداد پارامترهایی را که می‌توانستم به طور منطقی آزمایش کنم، محدود می‌کرد.
3. _حجم نمونه ناکافی:_ مجموعه داده نمونه من فقط 10000 رکورد بود. اگر زمان و سرور ابری بیشتری داشتم، استفاده از کل مجموعه داده 1.6 میلیون رکوردی را در دوره‌های بیشتر در نظر می‌گرفتم... اما پیش‌بینی می‌کنم اجرای این کار چند روز طول بکشد. و وقتی اندازه نمونه را کمی افزایش دادم، به نظر نمی‌رسید تفاوت زیادی داشته باشد. من همچنین استفاده از دوره‌های بیشتری را در طول آموزش مدل‌ام بررسی کرده بودم، اما به نظر می‌رسید که دقت پس از چندین دوره اول کاهش یافته است. من در نهایت از 10 دوره برای هر مدل استفاده کردم.
4. _ویژگی‌های مدل کافی نیست_ : مهم است که به خاطر داشته باشید که نظرات نظرات کاربران پیش‌بینی‌کننده ناقصی از رتبه‌بندی ستاره‌ای است که ممکن است بدهد. تنها با آموزش مدل خود بر روی نظرات کاربران، سایر عوامل پیش‌بینی‌کننده را که می‌تواند بر رتبه‌بندی ستاره یک کاربر تأثیر بگذارد، در نظر نگرفتم. این شامل نحوه بررسی سایر محصولات آنلاین، مشخصات جمعیتی آنها (به عنوان مثال سن، مکان، تحصیلات و غیره) یا سایر عوامل مرتبط با خود آلبوم موسیقی است. به‌جای پیش‌بینی رتبه‌بندی‌های ستاره‌ای، مدل من می‌تواند به‌عنوان پیش‌بینی‌کننده احساسات کاربر در مقیاس ۱ تا ۵ استفاده شود. دقت مدل من در پیش بینی در یک ستاره ثابت می کند که می تواند در انجام این کار موثر باشد.

به طور کلی، این یک تجربه یادگیری عالی برای آزمایش با معماری‌های مختلف شبکه عصبی در تکنیک‌های Keras و پردازش زبان طبیعی بود. در زیر، من جزئیات بیشتری را در مورد هر مرحله ای که در ایجاد مدل های خود برداشتم ارائه کرده ام.

# پیش پردازش داده های متنی:

پیش پردازش و بردارسازی در نهایت جزء بسیار وقت گیر این پروژه بود. این به دلیل تحقیق و آزمایش من بر روی تکنیک های مختلف بود. هدف نهایی پیش پردازش متن، ایجاد نوعی بردار (بردار) با نمایش عددی هر کلمه است. سپس این بردار عددی برای اهداف آموزشی و آزمایشی به یک مدل یادگیری ماشینی وارد می‌شود. جریان کلی پیش پردازشی که من استفاده کردم 1.) نمونه برداری از مجموعه داده، 2.) نشانه گذاری، 3.) عادی سازی، و 4.) بردار کردن همه داده های متنی من بود.

## **نمونه برداری از مجموعه داده:**

در اوایل، من متوجه دو نگرانی کلیدی در مورد منبع مجموعه داده های مرور آمازون شدم. اول اینکه خیلی بزرگ بود (1.6 میلیون رکورد) تا بتوانیم آموزش مدل های مختلف را در یک بازه زمانی معقول کامل کنیم. من در نهایت فقط 10000 رکورد را نمونه‌برداری کردم، که هنوز برای آموزش مدل‌های خاص زمان زیادی صرف می‌شود. درک بعدی من این بود که توزیع رتبه بندی ستاره ها بسیار کج بود. حدود 80 درصد رکوردها دارای رتبه 5 ستاره بودند، که من احساس کردم معنای امتیاز دقت من را تغییر می دهد (یعنی مدلی که پیش بینی می کند همه بررسی ها 5 ستاره باشند، 80 درصد دقت دارد که به طرز فریبنده ای بالاست). برای کاهش این موضوع در هنگام نمونه‌برداری تصادفی از رکوردهای 10k من، احتمال وزن بیشتری را برای نمونه‌گیری رکوردهای با کمتر از 5 ستاره قرار دادم. توزیع رتبه بندی ها قبل و بعد از نمونه گیری در زیر نشان داده شده است.

![](https://miro.medium.com/max/700/1*kWlUiwfkLcYbEGsGYMhCaA.png)

![](https://miro.medium.com/max/194/1*U9RYHqkpabyKDRk5CqFVnQ.png)

![](https://miro.medium.com/max/208/1*V2TMJwKkM0NrkTkQRrRCvA.png)تصویر سمت چپ توزیع اولیه رتبه بندی ستاره ها را نشان می دهد، تصویر سمت راست وزن های به روز شده را نشان می دهد.

## **توکن سازی** :

قدم بعدی من توکن کردن داده ها بود [به ](https://www.kdnuggets.com/2018/03/text-data-preprocessing-walkthrough-python.html)طوری که هر کلمه نشان دهنده یک ویژگی نشانه متمایز باشد. هنگام انجام این کار، من همچنین مطمئن شدم که "stopwords" را حذف کردم، که کلمات کاربردی رایج مانند "the"، "is" و "at" هستند. در زیر قطعه‌هایی از داده‌های من قبل و بعد از توکن‌سازی آورده شده است. انتظار می رود که نشانه هایی مانند "n't" از انقباضات (مثلاً انجام نده) تشکیل شوند.

![](https://miro.medium.com/max/700/1*-HjGbKt-IJdYHvO0nk4HYQ.png)

![](https://miro.medium.com/max/700/1*FUsm09g4ZXZPNUJvKgTS6w.png)

![](https://miro.medium.com/max/700/1*eLbzYpiqjVfnloQpiJsDMQ.png)

## **عادی سازی** :

پس از توکن کردن، داده‌های متن را بیشتر عادی کردم تا افزونگی را کاهش دهم. این کار با حذف هر گونه کاراکتر غیر ASCII، حذف علائم نگارشی، کوچک کردن همه چیز و جایگزینی اعداد با نمایش متنی (500 = پانصد) انجام شد. من قطعات کد را از [اینجا ](https://www.kdnuggets.com/2018/03/text-data-preprocessing-walkthrough-python.html).

![](https://miro.medium.com/max/700/1*Re5F-UqihgabklNn9kV7aQ.png)

من همچنین از کلمه نویسی استفاده کردم که نوعی [تکنیک ](https://nlp.stanford.edu/IR-book/html/htmledition/stemming-and-lemmatization-1.html). این کار کلمات، به ویژه افعال را به شکل ریشه و زمان حال عادی می کند. قطعه ای از همان رکورد بازبینی پس از عادی سازی در زیر نشان داده شده است. توجه داشته باشید که چگونه "شنیده" به "گوش دادن" و "فکر" به "فکر" تبدیل می شود.

![](https://miro.medium.com/max/700/1*u4y8kliiM80XCcwXbq2eIw.png)

![](https://miro.medium.com/max/700/1*FsXhfPDaKfHXqFLmjoPuNw.png)

## **برداری** :

آخرین و پیچیده‌ترین مرحله، بردار کردن داده‌های متنی به عنوان یک ماتریس عددی برای ورودی در الگوریتم‌های من است. تکنیک های زیادی برای انجام این کار وجود دارد. سه روشی که من مورد بررسی قرار دادم عبارت بودند از Bag of Words (BOW)، آموزش بردار جاسازی کلمه از ابتدا، و استفاده از الگوریتم از پیش آموزش داده شده بردار جاسازی کلمه Global Vectors for Word Representation (GloVe).

**تعبیه BOW:** با این روش **از** بردارها ایجاد می شود که نشان دهنده بسامد هر کلمه است. هر بردار مربوط به یک بررسی است و عرض هر بردار تعداد همه کلمات متمایز در کل پیکره در تمام رکوردها است. در بردار هر بررسی، فراوانی هر کلمه پر شده است. یک [مثال ](https://victorzhou.com/blog/bag-of-words/)در زیر نشان داده شده است. در حالی که این ساده ترین روش برای پیاده سازی است، اما دارای چندین [اشکال ](https://www.analyticsvidhya.com/blog/2020/02/quick-introduction-bag-of-words-bow-tf-idf/)است. با افزایش تعداد رکوردها و واژگان کلمات، بردارها با مقادیر غیر صفر بسیار گسترده می شوند. همچنین، بسامد کلمه برای بافت یا ترتیب کلمات در نظر گرفته نمی شود.

![](https://miro.medium.com/max/700/1*VJglsARn7kWx6zZO9JqdFg.png)

در زیر یک قطعه کد از یک تست BOW است که من با الگوریتم SVM روی 1000 رکورد نمونه انجام دادم. همچنین نتایج عملکرد را در 250 رکورد در داده های اعتبارسنجی من نشان می دهد (75/25 تقسیم).

![](https://miro.medium.com/max/700/1*uPf_u2zzA5VyTk4LPpsYGA.png)

![](https://miro.medium.com/max/337/1*6hscOXUh6E3nrfIYCrKL4w.png)

![](https://miro.medium.com/max/281/1*78yClGtMtmvOaluz5qXkmg.png)

**جاسازی کلمات آموزش داده شده به صورت دستی:** رویکرد دوم من ایجاد جاسازی کلمات بود که به صورت دستی در مدل من آموزش داده می شد. سه رویکرد کلی برای برداری توکن و جاسازی کلمه وجود دارد:

1. کلماتی که توسط هر کلمه به عنوان یک بردار نشان داده می شوند
2. کاراکترهایی که توسط هر کاراکتر به عنوان یک بردار نمایش داده می شوند
3. N گرم از کلمات/شخصیت ها به صورت بردار نمایش داده می شوند. N-gram ها گروه های همپوشانی چند کلمه/شخصیت بعدی در متن هستند. برای مثال، می‌توانید N=3 را برای جستجوی ترکیب‌های کلمه‌ای مانند «من آب نبات دوست دارم» انتخاب کنید. این [روش ](https://suyashkhare619.medium.com/how-to-deal-with-multi-word-phrases-or-n-grams-while-building-a-custom-embedding-eec547d1ab45)اگر کلمات را به روش های مشابه استفاده کنند، به شیوه ای مشابه نشان می دهد. رنگ آبی نمایش عددی بسیار مشابهی با قرمز نسبت به ماهی دارد.

من روش شماره 1 را انتخاب کردم، زیرا احساس کردم بردار کردن هر کاراکتر برای چنین مجموعه داده بزرگی ناکارآمد است و زمان زیادی برای آزمایش پارامترهای N-gram نداشتم. در این روش شماره 1، من رمزگذاری یک‌طرفه و جاسازی کلمه را بررسی کردم. رمزگذاری تک داغ یک نشانگر باینری 0/1 را نشان می دهد که آیا یک کلمه در میان کل مجموعه کلمات متمایز برای هر رکورد وجود دارد یا خیر. اما مانند BOW، یک اشکال بزرگ رمزگذاری تک داغ این است که بردارهای ورودی بسیار گسترده ای ایجاد می کند و ترتیب کلمات (به عنوان مثال زمینه) را در نظر نمی گیرد.

در عوض، من در نهایت از تکنیک جاسازی کلمه استفاده کردم که بردارهایی با اندازه و متراکم ایجاد می کند که حداکثر اندازه آنها بر اساس تعداد کلمات در طولانی ترین نظر کاربر است. این بردار شامل اعداد نمایه شده متمایز مرتبط با کلمات داده شده در بررسی کاربر یک رکورد است. برای نظرات کاربران که کوتاه‌تر هستند، بردارها با صفر اضافه می‌شوند. تصویر زیر نشان می‌دهد که چگونه داده‌های توکن‌سازی شده به دنباله‌های آموزشی تبدیل می‌شوند، که سپس به بردارهایی با اندازه مساوی اضافه می‌شوند. در مثال [زیر ](https://www.kdnuggets.com/2020/03/tensorflow-keras-tokenization-text-data-prep.html)، از آنجایی که اولین دنباله متن فقط سه کلمه است، بقیه بردار با صفر پر شده است.

![](https://miro.medium.com/max/645/1*by-0WDL31MdetbYlGAHvEw.png)

![](https://miro.medium.com/max/700/1*Py6aID0HMHcv_G9smar32A.png)

در Keras، کتابخانه‌های مفیدی برای توکن‌سازی، پد و بردار کردن داده‌ها وجود دارد. در زیر نمونه‌ای وجود دارد که یک رکورد بازبینی نمونه را نشانه‌گذاری می‌کند و از یک قطعه کد پیروی می‌کند تا بردارها را به اندازه یکسان قرار دهد.

![](https://miro.medium.com/max/700/1*JnEOu3O6unPW-ggBxytWlw.png)

![](https://miro.medium.com/max/700/1*5k9MwZvIOPwtCFbONGp5TA.png)

**جاسازی GloVe** : رویکرد سوم من استفاده از جاسازی GloVe از قبل آموزش دیده بود. این تعبیه رایگان [قابل دانلود ](https://nlp.stanford.edu/projects/glove/)، وزن‌هایی را برای کلمات اولیه‌سازی کرده است، که عمدتاً از ایجاد ماتریس‌های همزمانی کلمه در کل مجموعه متن ناشی می‌شوند. Keras این توانایی را می دهد که این دیکشنری های تعبیه شده را در تابع جاسازی یک مدل شبکه عصبی ترکیب کند. در حالی که از این تعبیه برای بذر کردن مدل استفاده شد، من انتخاب کردم که آنها در طول آموزش مدل به روز شوند. اگر زمان بیشتری داشتم، دیگر کتابخانه‌های تعبیه‌شده از پیش آموزش‌دیده‌ای که می‌توانستم کاوش [می‌کردم Word2Vec ](https://www.tensorflow.org/tutorials/text/word2vec)و [TF-IDF ](https://nlp.stanford.edu/IR-book/html/htmledition/tf-idf-weighting-1.html)بودند. همانطور که از قطعه کد زیر مشاهده می شود، اگر حداکثر ابعاد جاسازی را 50 تنظیم کنم، کتابخانه GloVe 93٪ از کل کلمات موجود در مجموعه متن داده های من را تشکیل می دهد.

![](https://miro.medium.com/max/531/1*Ujm0kE6cqhopPTXRMYtgMg.png)

# مدل سازی:

به دلیل حجم زیاد داده، به ویژه زمانی که متن بردار است، من تمایل داشتم با استفاده از شبکه های عصبی کاوش کنم. من به ویژه با استفاده از CNN، که [اغلب ](https://arxiv.org/abs/1412.1058)در مسائل طبقه بندی متن استفاده می شود، مجذوب شدم. و من کنجکاو بودم که چگونه در برابر یک الگوریتم سنتی/کمتر فشرده ML (SVM)، که همچنین یک [انتخاب ](https://www.cs.cornell.edu/people/tj/publications/joachims_98a.pdf)برای طبقه بندی متن است، عمل می کند.

## **ماشین‌های بردار پشتیبانی (SVM):**

برای مدل SVM خود، از پارامترهای پیش‌فرض برای آموزش داده‌های متنی خود استفاده کردم. هیچ جریمه تنظیمی اعمال نکرد و از هسته تابع پایه شعاعی استفاده کرد. بردارهای ورودی از تکنیک رمزگذاری BOW ایجاد شدند. از آنجایی که SVM تمرکز پروژه من نبود، زمان زیادی را صرف تنظیم مقادیر پارامتر مدل نکردم و آن را بیشتر به عنوان یک مدل پایه در نظر گرفتم.

![](https://miro.medium.com/max/700/1*4T10ngBw4hh30EbG9uoltw.png)

نتایج مدل پایه SVM من در زیر آمده است. دقت در 2500 رکورد اعتبار سنجی \~62٪ بود. همچنین دقت در مجموعه داده آموزشی تنها 69.1 درصد بود که نشان می‌دهد این الگوریتم چندان مؤثر نبوده است.

![](https://miro.medium.com/max/613/1*cRok3oRZY9Jbwvz2fp-LHQ.png)

## **شبکه عصبی عمیق (DNN)** :

من یک DNN را با استفاده از BOW و تکنیک‌های بردارسازی متن جاسازی کلمه را آموزش دادم که در بالا توضیح دادم. من از Keras' Sequential Model API استفاده کردم که در آن لایه ها به ترتیب اضافه می شوند. این [آموزش ](https://realpython.com/python-keras-text-classification/#convolutional-neural-networks-cnn)راهنمای بسیار مفیدی هم برای پیاده سازی Keras و هم برای دریافت درک پایه از شبکه های عصبی بود. من سعی خواهم کرد این را در زیر خلاصه کنم، و _صورت مورب_ عناصر کلیدی یک NN را که دارای تغییرات متعددی است که من آنها را آزمایش کردم

**\[خیلی\] توصیف شبکه‌های عصبی در سطح بالا:** شبکه‌های عصبی شامل گره‌هایی هستند که داده‌های آموزشی را از یک لایه ورودی تغذیه می‌کنند ← یک یا چند _لایه پنهان_ که در آن تمام آموزش‌های تکراری انجام می‌شود ← یک لایه خروجی که حاوی احتمالات پیش‌بینی‌کننده وزنی است. لایه خروجی یک گره برای هر کلاس پیش بینی خواهد داشت (در این مورد 5). یک نمودار ساده در زیر آمده است.

![](https://miro.medium.com/max/440/1*7ZrwJcytqvhaj7g9_Q-2yg.png)

در طول یک NN، هر لایه از گره های ورودی در یک وزن محاسبه شده و متغیر بایاس ضرب می شود تا گره های خروجی لایه بعدی تولید شود. وزن‌های ورودی اولیه یک مدل به‌طور تصادفی تخصیص داده می‌شوند و از طریق روشی به نام backpropogation آموزش داده می‌شوند. این روش از _بهینه سازها_ برای کاهش خطا بین خروجی هدف محاسبه شده و مورد نظر استفاده می کند. هدف بهینه ساز کاهش _تابع تلفات است_ که به این صورت است که خطا را کمی می کنیم. در طول انتشار پس‌انداز، وزن هر لایه ورودی از طریق یک _تابع فعال‌سازی_ .

**پارامترهای کلیدی در مدل من** :

1. _لایه‌های پنهان_ : من یک شبکه عصبی «عمیق» ساختم، به این معنی که چندین لایه پنهان وجود داشت که امکان آموزش اضافی را فراهم می‌کرد. در مدل من با تعبیه‌های آموزش‌دیده دستی، مجبور شدم یک لایه جاسازی در برداریم اضافه کنم. این در مدل BOW من مورد نیاز نبود. برای کمک به تعمیم مدل، اضافه کردن یک [لایه Dropout ](https://machinelearningmastery.com/dropout-for-regularizing-deep-neural-networks/)تصادفی گره‌ها را در طول پس‌پروپولیشن رها می‌کند. با این حال، تأثیر محدودی بر دقت عملکرد داشت.
2. _بهینه ساز_ : من از [Adam ](https://machinelearningmastery.com/adam-optimization-algorithm-for-deep-learning/)، زیرا به طور گسترده استفاده می شود و [عملکرد ](https://datascience.stackexchange.com/questions/10523/guidelines-for-selecting-an-optimizer-for-training-neural-networks)خوبی در انواع مدل ها دارد.
3. _تابع ضرر_ : من از یک تابع از دست دادن متقابل آنتروپی طبقه بندی شده استفاده کردم زیرا این یک مشکل طبقه بندی چند کلاسه بود.
4. _تابع فعال سازی_ : امکان اعمال توابع فعال سازی مختلف به لایه های مختلف در یک NN وجود دارد. برای لایه اولیه، از 10 نورون با تابع فعال سازی Relu استفاده کردم. من از تابع فعال سازی softmax استفاده کردم که برای مشکلات چند کلاسه ایده آل است زیرا احتمال هر برچسب کلاس را خروجی می دهد. من همچنین اضافه کردن یک تابع تنظیم کننده به لایه Dropout خود را آزمایش کردم.

قطعه کد زیر نشان می دهد که چگونه DNN در Keras ساخته شده است.

![](https://miro.medium.com/max/700/1*xteQcCbuEj4BEMD_X1suCg.png)

تعریف پارامترهای مدل

![](https://miro.medium.com/max/700/1*BRFysVBtxXzsT0a2vbYUow.png)

آموزش مدل

![](https://miro.medium.com/max/700/1*8Bu__15DzJHQoVhlfyNatQ.png)

مشاهده نتایج عملکرد

**نتایج DNN:**

همانطور که در زیر نشان داده شده است، هر دو مدل DNN من در 2500 رکورد اعتبار سنجی حدود 60 درصد دقت داشتند. دقت تمرین بالا (92-95٪) نشان می دهد که مدل ها بسیار بیش از حد مناسب بودند. با این حال، همانطور که در بالا ذکر شد، DNN من با BOW بهترین عملکرد را در پیش‌بینی رتبه‌بندی ستاره در یک ستاره (۹۱.۲%) داشت.

![](https://miro.medium.com/max/632/1*lEbELIrigySbxUR_iAQIQg.png)

هنگام برازش مدل با داده های آموزشی، به نظر می رسید که دقت در داده های اعتبارسنجی پس از \~ 5 دوره شروع به کاهش کرد. در زیر، محور X به دوره‌ها اشاره دارد و محور Y نسبتی از درجه‌بندی ستاره‌ها است که به درستی پیش‌بینی شده است.

![](https://miro.medium.com/max/575/1*1uRNlvIVlkad85Zlgno7BQ.png)

## **شبکه عصبی کانولوشن (CNN)** :

**معماری و روش شناسی:**

CNN ها نوعی از DNN هستند که از نظر معماری مشابه هستند، اما دارای برخی از لایه ها و پارامترهای کلیدی اضافی هستند که در نمودار [زیر ](https://towardsdatascience.com/understanding-how-convolutional-neural-network-cnn-perform-text-classification-with-word-d2ee64b9dd0b)است.

![](https://miro.medium.com/max/700/1*0tu1udjlyJrTwTW9MP-17w.png)

**لایه 1 - لایه ورودی:** در سمت چپ، لایه ورودی کلمات را در بردارهایی با ابعاد کم جاسازی می کند. این کار توسط تابع Embedding در Keras انجام می شود، مشابه آنچه با DNN های من انجام شد.

در مدل CNN من که از تعبیه‌های کلمه GloVe از قبل آموزش‌دیده استفاده می‌کرد، این را با ایجاد یک لایه جاسازی در گام اولیه‌ام در معماری CNN فراخوانی کردم. این کار با تنظیم وزن‌ها برای برابری با ماتریس جاسازی که وارد کردم انجام شد. طول ورودی حداکثر طول توالی‌های برداری بالشتکی بود که من در پردازش متن ایجاد کرده بودم (توضیح داده شده در بالا). در حالی که این تعبیه‌ها باعث ایجاد مدل من شدند، من ترجیح دادم جاسازی را طوری تنظیم کنم که قابل آموزش باشد و وزن‌ها به طور مداوم در طول آموزش مدل به روز شوند.

**لایه 2 - لایه کانولوشنال:** این لایه دوم از طریق اولین لایه ورودی از بردارهای کلمه جاسازی شده در می‌آید. با استفاده از فیلترهای مختلف، ضربات عاقلانه عناصر را برای هر کانولوشن با یک تابع فعال سازی (مانند یک DNN) انجام می دهد. از فیلترهای متعدد در اندازه های مختلف بر روی زیر مجموعه های توکن در ماتریس ورودی من استفاده می کند. یک مثال در نمودار زیر در سمت چپ مشاهده می‌شود، که در آن یک فیلتر 2x5 از طریق دو کلمه مجاور در یک جمله ورودی (که در ماتریس تعبیه شده نشان داده شده است) تکرار می‌شود. سپس محصولی از نظر عنصر تولید می کند که در لایه خروجی نقشه ویژگی (0.51) ثبت می شود. این دنباله برای هر خوشه از کلماتی که فیلتر می کند تکرار می شود.

توابع فعال سازی غیرخطی مختلفی وجود دارد که [می توان ](https://realpython.com/python-keras-text-classification/#convolutional-neural-networks-cnn)در این لایه استفاده کرد، مانند Relu. در مدل خود من از یک تابع فعال سازی softmax استفاده کردم و از 128 فیلتر با ابعاد 5x5 با گام 1 استفاده کردم. این لایه از طریق زیر مجموعه های مختلف رمز در ورودی رشته متن من فیلتر می شود. من نیز مانند DNN خود از بهینه ساز Adam و توابع از دست دادن آنتروپی متقاطع در لایه های متراکم خود استفاده کردم.

**لایه 3 - لایه ادغام: لایه** ادغام در یک CNN از خروجی نقشه ویژگی نمونه برداری می کند تا یک [نسخه خلاصه و تعمیم یافته از ویژگی های شناسایی شده در ورودی ارائه ](https://machinelearningmastery.com/pooling-layers-for-convolutional-neural-networks/)دهد. بنابراین، حتی اگر لایه کانولوشن تغییر کوچکی را در ورودی ویژگی تشخیص دهد (مانند ترتیب کلمات)، نقشه ویژگی تلفیقی می‌تواند همان نتیجه را داشته باشد.

برخلاف نمودار بالا، من از Global Max Pooling استفاده کردم که کل نقشه ویژگی را به یک مقدار واحد پایین می آورد. همچنین خروجی مدل من (سمت راست) به جای 2، 5 کلاس (برای هر ستاره) داشت.

**تنظیم Hyperparameter:** من از قابلیت Gridsearch Python برای آزمایش ترکیب پارامترهای بهینه برای مدل CNN GloVe استفاده کردم. خروجی این نتایج برای 20 ترکیب برتر اجرایی در زیر آمده است. پارامترهای CNN که من آزمایش کردم عبارت بودند از تابع فعال‌سازی، نرخ ترک تحصیل، نرخ یادگیری و تعداد نورون‌ها در لایه اولیه. من در نهایت از نرخ یادگیری پیش‌فرض 0.1، 5 نورون، 0.2 نرخ ترک تحصیل و یک تابع فعال‌سازی softmax استفاده کردم.

![](https://miro.medium.com/max/700/1*U8dPdurD0vdYvHBM_D_XbQ.png)

در زیر یک قطعه کد از نحوه کدنویسی CNN با کتابخانه Keras پایتون آمده است.

![](https://miro.medium.com/max/700/1*IVcCsIQ5PywIlFHV3_fJYA.png)

**نتایج CNN:**

علیرغم تمام تنظیم‌ها در مدل CNN من (و زمان آموزش بسیار طولانی‌تر است)، کمی بدتر از مدل BOW شبکه عصبی من عمل کرد. سی ان ان من با جاسازی GloVe 57 درصد از 2500 رکورد تأیید اعتبار داشت. و CNN من با جاسازی کلمه دستی 56.2 درصد دقت داشت. مانند DNN های من، هر دوی آنها دقت بالایی در نمونه آموزشی داشتند (\~93%)، که به معنی بیش از حد مناسب بودن است. با این حال، من یک بار دیگر خوشحال شدم و از اینکه آنها دقت 90٪ در پیش بینی دقیق در یک ستاره داشتند، خوشحالم.

![](https://miro.medium.com/max/666/1*-Xb47m2cw3cvylbn7PefcA.png)

![](https://miro.medium.com/max/666/1*-Xb47m2cw3cvylbn7PefcA.png)

دوباره، مانند DNN های من، نرخ های منحنی یادگیری زیر نشان می دهد که دقت در داده های اعتبارسنجی من پس از \~ 5 دوره شروع به کاهش کرده است. اگر زمان بیشتری به من داده شود، به آزمایش پارامترهای مختلف - به ویژه پارامترهای فیلتر در لایه Convolutional CNN خود ادامه خواهم داد.

![](https://miro.medium.com/max/648/1*TIimuwXxAYCuA7wjox7tAg.png)

همانطور که به یادگیری بیشتر در مورد تکنیک‌های مدل‌سازی NLP و شبکه‌های عصبی ادامه می‌دهم، امیدوارم این پروژه را دوباره بررسی کنم و عملکرد مدل را به طور بالقوه بهبود بخشم.